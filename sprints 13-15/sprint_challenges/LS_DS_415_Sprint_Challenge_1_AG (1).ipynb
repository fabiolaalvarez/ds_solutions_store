{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernel_info": {
      "name": "u4-s1-nlp"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    },
    "nteract": {
      "version": "0.15.0"
    },
    "toc-autonumbering": false,
    "colab": {
      "provenance": []
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "8yhE2Y_oyXpi"
      },
      "source": [
        "#!pip install pyLDAvis"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s_TG_TlgdXEF"
      },
      "source": [
        "# Sprint Challenge\n",
        "## *Data Science Unit 4 Sprint 1*\n",
        "\n",
        "After a week of Natural Language Processing, you've learned some cool new stuff: how to process text, how turn text into vectors, and how to model topics from documents. Apply your newly acquired skills to one of the most famous NLP datasets out there: [Yelp](https://www.yelp.com/dataset). As part of the job selection process, some of my friends have been asked to create analysis of this dataset, so I want to empower you to have a head start.  \n",
        "\n",
        "The real dataset is massive (almost 8 gigs uncompressed). I've sampled the data for you to something more manageable for the Sprint Challenge. You can analyze the full dataset as a stretch goal or after the sprint challenge. As you work on the challenge, I suggest adding notes about your findings and things you want to analyze in the future.\n",
        "\n",
        "## Challenge Objectives\n",
        "Successfully complete all these objectives to earn full credit.\n",
        "\n",
        "**Successful completion is defined as passing all the unit tests in each objective.**  \n",
        "\n",
        "Each unit test that you pass is 1 point.\n",
        "\n",
        "There are 5 total possible points in this sprint challenge.\n",
        "\n",
        "\n",
        "There are more details on each objective further down in the notebook.*\n",
        "* <a href=\"#p1\">Part 1</a>: Write a function to tokenize the yelp reviews\n",
        "* <a href=\"#p2\">Part 2</a>: Create a vector representation of those tokens\n",
        "* <a href=\"#p3\">Part 3</a>: Use your tokens in a classification model on yelp rating\n",
        "* <a href=\"#p4\">Part 4</a>: Estimate & Interpret a topic model of the Yelp reviews\n",
        "\n",
        "____\n",
        "\n",
        "# Before you submit your notebook you must first\n",
        "\n",
        "1) Restart your notebook's Kernel\n",
        "\n",
        "2) Run all cells sequentially, from top to bottom, so that cell numbers are sequential numbers (i.e. 1,2,3,4,5...)\n",
        "- Easiest way to do this is to click on the **Cell** tab at the top of your notebook and select **Run All** from the drop down menu.\n",
        "\n",
        "3) Comment out the cell that generates a pyLDAvis visual in objective 4 (see instructions in that section).\n",
        "____"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LwFL5T1CdXEJ"
      },
      "source": [
        "\n",
        "\n",
        "### Import Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "7bec125eb29f89460cf0c19ba9aa9a2f",
          "grade": false,
          "grade_id": "cell-395851cd95d17235",
          "locked": false,
          "schema_version": 3,
          "solution": true,
          "task": false
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hENi7RgadXEK",
        "outputId": "d04c9201-d02b-477f-8645-2c380b9a32eb"
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load reviews from URL\n",
        "data_url = 'https://raw.githubusercontent.com/LambdaSchool/data-science-practice-datasets/main/unit_4/unit1_nlp/review_sample.json'\n",
        "\n",
        "# Import data into a DataFrame named df\n",
        "df = pd.read_json(data_url, lines=True)\n",
        "df.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(10000, 9)"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "356579363f311da83f4ef7abaf3c9212",
          "grade": true,
          "grade_id": "cell-cb5006475e42b8f9",
          "locked": true,
          "points": 1,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "lL1s-GfYdXEM"
      },
      "source": [
        "# Visible Testing\n",
        "assert isinstance(df, pd.DataFrame), 'df is not a DataFrame. Did you import the data into df?'\n",
        "assert df.shape[0] == 10000, 'DataFrame df has the wrong number of rows.'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4YFW9m-cdXEM"
      },
      "source": [
        "## Part 1: Tokenize Function\n",
        "<a id=\"#p1\"></a>\n",
        "\n",
        "Complete the function `tokenize`. Your function should\n",
        "- accept one document at a time\n",
        "- return a list of tokens\n",
        "\n",
        "You are free to use any method you have learned this week."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OEJsNxEUdXEN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "edcc62b5-b069-477b-b4e3-3198e1649331"
      },
      "source": [
        "# Optional: Consider using spaCy in your function. The spaCy library can be imported by running this cell.\n",
        "# A pre-trained model (en_core_web_sm) has been made available to you in the CodeGrade container.\n",
        "# If you DON'T need use the en_core_web_sm model, you can comment it out below.\n",
        "import spacy\n",
        "nlp = spacy.load('en_core_web_sm')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/torch/cuda/__init__.py:497: UserWarning: Can't initialize NVML\n",
            "  warnings.warn(\"Can't initialize NVML\")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "4837ed2a1cc13057ba40203859d46ff6",
          "grade": false,
          "grade_id": "cell-3d570d5a1cd6cb64",
          "locked": false,
          "schema_version": 3,
          "solution": true,
          "task": false
        },
        "id": "7LFowsh6dXEO"
      },
      "source": [
        "def tokenize(doc):\n",
        "  \"\"\"\n",
        "  Using SpaCy, we take in a doc and return a list of tokens as lemmas\n",
        "  Removes stop words and punctuation\n",
        "  \"\"\"\n",
        "  document = nlp(doc)\n",
        "\n",
        "  return [token.lemma_.strip() for token in document if (token.is_stop != True) and (token.is_punct != True)]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def tokenize(doc):\n",
        "  lemma_list = [token.lemma_.lower().strip() for token in nlp(doc) if (not token.is_stop) and (not token.is_punct) and (not token.is_space)]\n",
        "  return lemma_list"
      ],
      "metadata": {
        "id": "WhWGjhIY2uEh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenize(df.sample(n=1)[\"text\"].iloc[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "We9qGal72_1B",
        "outputId": "2ab0561c-3fe8-4c2c-f4c9-692b242598fe"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['love',\n",
              " 'Grimaldi',\n",
              " 'visit',\n",
              " 'awful',\n",
              " 'location',\n",
              " 'server',\n",
              " 'Dustin',\n",
              " 'abhorrent',\n",
              " 'rude',\n",
              " 'order',\n",
              " 'drink',\n",
              " 'rude',\n",
              " 'order',\n",
              " 'food',\n",
              " 'asshole',\n",
              " 'get',\n",
              " 'drink',\n",
              " 'refill',\n",
              " 'chore',\n",
              " 'glass',\n",
              " 'deliver',\n",
              " 'second',\n",
              " 'pizza',\n",
              " 'say',\n",
              " 'refill',\n",
              " 'come',\n",
              " 'manage',\n",
              " 'drink',\n",
              " 'refill',\n",
              " 'table',\n",
              " 'make',\n",
              " 'eye',\n",
              " 'contact',\n",
              " 'come',\n",
              " 'ready',\n",
              " 'drop',\n",
              " 'ticket',\n",
              " 'point',\n",
              " 'ask',\n",
              " 'drink',\n",
              " 'refill',\n",
              " 'entire',\n",
              " 'PIZZA',\n",
              " 'FINISHED',\n",
              " 'lean',\n",
              " 'entire',\n",
              " 'table',\n",
              " 'refill',\n",
              " 'shove',\n",
              " 'crotch',\n",
              " 'mother',\n",
              " 'face',\n",
              " 'way',\n",
              " 'guess',\n",
              " 'kill',\n",
              " 'walk',\n",
              " 'round',\n",
              " 'table',\n",
              " 'love',\n",
              " 'pizza',\n",
              " 'plenty',\n",
              " 'location',\n",
              " 'treat',\n",
              " 'like',\n",
              " 'want',\n",
              " 'dad',\n",
              " 'regular',\n",
              " 'specific',\n",
              " 'location',\n",
              " 'favorite',\n",
              " 'spot',\n",
              " 'local',\n",
              " 'high',\n",
              " 'tolerance',\n",
              " 'bad',\n",
              " 'service',\n",
              " 'bad',\n",
              " 'experience',\n",
              " 'height',\n",
              " 'day',\n",
              " 'restaurant',\n",
              " 'opt',\n",
              " 'dine',\n",
              " 'lunch',\n",
              " 'rush',\n",
              " 'care',\n",
              " 'Dustin',\n",
              " 'have',\n",
              " 'bad',\n",
              " 'day',\n",
              " 'able',\n",
              " 'tell',\n",
              " 'offer',\n",
              " 'serve',\n",
              " 'slice',\n",
              " 'happen',\n",
              " 'grimaldi',\n",
              " 'offer',\n",
              " 'fresh',\n",
              " 'plate',\n",
              " 'second',\n",
              " 'pizza',\n",
              " 'usually',\n",
              " 'decline',\n",
              " 'nice',\n",
              " 'ask',\n",
              " 'complain',\n",
              " 'management',\n",
              " 'think',\n",
              " 'spoil',\n",
              " 'father',\n",
              " 'favorite',\n",
              " 'spot',\n",
              " 'want',\n",
              " 'leave',\n",
              " 'absolutely',\n",
              " 'horrible',\n",
              " 'experience']"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "2181ca9d36070260b1f75dcfd9e58965",
          "grade": true,
          "grade_id": "cell-02da164f6fbe730a",
          "locked": true,
          "points": 1,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "2FLMpWkXdXEP"
      },
      "source": [
        "'''Testing'''\n",
        "assert isinstance(tokenize(df.sample(n=1)[\"text\"].iloc[0]), list), \"Make sure your tokenizer function accepts a single document and returns a list of tokens!\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W_471qkWdXES"
      },
      "source": [
        "## Part 2: Vector Representation\n",
        "<a id=\"#p2\"></a>\n",
        "1. Create a vector representation of the reviews (i.e. create a doc-term matrix).\n",
        "2. Write a fake review and query for the 10 most similar reviews, print the text of the reviews. Do you notice any patterns?\n",
        "    - Given the size of the dataset, use `NearestNeighbors` model for this."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "d70a0a1a96cf8406c60b17e50b255a1a",
          "grade": false,
          "grade_id": "cell-0e96491cb529202c",
          "locked": false,
          "schema_version": 3,
          "solution": true,
          "task": false
        },
        "id": "JTfNMifYdXET",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "30e511fe-5cd4-4367-a27d-5e66f198ff57"
      },
      "source": [
        "%%time\n",
        "# Create a vector representation of the reviews\n",
        "# Name that doc-term matrix \"dtm\"\n",
        "\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "\n",
        "vect = CountVectorizer()\n",
        "vect.fit(df['text'])\n",
        "dtm = vect.transform(df['text'])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 1.84 s, sys: 87.6 ms, total: 1.92 s\n",
            "Wall time: 2.29 s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y4IjTbvBjeVl",
        "outputId": "e7ca7cb1-4e1d-48fc-d913-05aedc0e29f1"
      },
      "source": [
        "print(dtm)\n",
        "\n",
        "type(dtm)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  (0, 185)\t1\n",
            "  (0, 278)\t1\n",
            "  (0, 566)\t1\n",
            "  (0, 600)\t1\n",
            "  (0, 636)\t1\n",
            "  (0, 833)\t1\n",
            "  (0, 1227)\t1\n",
            "  (0, 1295)\t1\n",
            "  (0, 1357)\t1\n",
            "  (0, 1483)\t1\n",
            "  (0, 1500)\t4\n",
            "  (0, 2067)\t1\n",
            "  (0, 2598)\t1\n",
            "  (0, 2608)\t2\n",
            "  (0, 2881)\t1\n",
            "  (0, 2938)\t1\n",
            "  (0, 3889)\t1\n",
            "  (0, 3890)\t1\n",
            "  (0, 3977)\t1\n",
            "  (0, 4067)\t1\n",
            "  (0, 5508)\t1\n",
            "  (0, 5818)\t1\n",
            "  (0, 6080)\t1\n",
            "  (0, 9143)\t3\n",
            "  (0, 9523)\t1\n",
            "  :\t:\n",
            "  (9999, 25201)\t1\n",
            "  (9999, 25443)\t1\n",
            "  (9999, 25769)\t1\n",
            "  (9999, 25838)\t1\n",
            "  (9999, 25868)\t1\n",
            "  (9999, 26489)\t10\n",
            "  (9999, 26492)\t1\n",
            "  (9999, 26507)\t1\n",
            "  (9999, 26509)\t1\n",
            "  (9999, 26522)\t4\n",
            "  (9999, 26609)\t1\n",
            "  (9999, 26714)\t3\n",
            "  (9999, 26761)\t1\n",
            "  (9999, 26765)\t1\n",
            "  (9999, 26783)\t1\n",
            "  (9999, 26818)\t2\n",
            "  (9999, 26907)\t2\n",
            "  (9999, 26913)\t1\n",
            "  (9999, 26945)\t1\n",
            "  (9999, 26951)\t1\n",
            "  (9999, 27025)\t1\n",
            "  (9999, 27029)\t1\n",
            "  (9999, 27162)\t1\n",
            "  (9999, 27235)\t2\n",
            "  (9999, 27246)\t1\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "scipy.sparse.csr.csr_matrix"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "32b220e23c9aa1f602f08d1c2e879d0a",
          "grade": false,
          "grade_id": "cell-3d5bc610a8ec6b24",
          "locked": false,
          "schema_version": 3,
          "solution": true,
          "task": false
        },
        "id": "VkulMKANdXEU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "435ea989-df50-4310-9279-3e5ca7d3c3e9"
      },
      "source": [
        "# Create and fit a NearestNeighbors model named \"nn\"\n",
        "from sklearn.neighbors import NearestNeighbors\n",
        "\n",
        "nn = NearestNeighbors(n_neighbors=10, algorithm='kd_tree')\n",
        "nn.fit(dtm)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/neighbors/_base.py:504: UserWarning: cannot use tree with sparse input: using brute force\n",
            "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "NearestNeighbors(algorithm='kd_tree', n_neighbors=10)"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "d270ed23df3c7d3c6cf08ab174ccaf9e",
          "grade": true,
          "grade_id": "cell-c43704dcff67e99b",
          "locked": true,
          "points": 1,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "A08B73rPdXEU"
      },
      "source": [
        "'''Testing.'''\n",
        "assert nn.__module__ == 'sklearn.neighbors._unsupervised', ' nn is not a NearestNeighbors instance.'\n",
        "assert nn.n_neighbors == 10, 'nn has the wrong value for n_neighbors'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "3da2ced9f187ed0aa1a890785e2ba00e",
          "grade": false,
          "grade_id": "cell-496203e8746296ca",
          "locked": false,
          "schema_version": 3,
          "solution": true,
          "task": false
        },
        "id": "R8i5OXWKdXEV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2bbc4099-24ec-4b1a-a569-a8c4bf73c65d"
      },
      "source": [
        "# Create a fake review and find the 10 most similar reviews\n",
        "\n",
        "fake_review = [\"\"\"\n",
        "Probably the best coffee place in SJ. Super friendly staff! Offers takeout coffee with pre-order during the pandemic, as well as pastry items and other things. I got a french press from them as my former one broke\n",
        "\"\"\" ]\n",
        "doc = vect.transform(fake_review)\n",
        "neigh_dist, neigh_index = nn.kneighbors(doc)\n",
        "neigh_index\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[9981, 4569, 4730, 5983, 4626, 5129,  964, 6810, 7586, 8858]])"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5pp9rs9-dXEV"
      },
      "source": [
        "## Part 3: Classification\n",
        "<a id=\"#p3\"></a>\n",
        "Your goal in this section will be to predict `stars` from the review dataset.\n",
        "\n",
        "1. Create a pipeline object with a sklearn `CountVectorizer` or `TfidfVector` and any sklearn classifier.\n",
        "    - Use that pipeline to train a model to predict the `stars` feature (i.e. the labels).\n",
        "    - Use that Pipeline to predict a star rating for your fake review from Part 2.\n",
        "\n",
        "\n",
        "\n",
        "2. Create a parameter dict including `one parameter for the vectorizer` and `one parameter for the model`.\n",
        "    - Include 2 possible values for each parameter\n",
        "    - **Use `n_jobs` = 1**\n",
        "    - Due to limited computational resources on CodeGrader `DO NOT INCLUDE ADDITIONAL PARAMETERS OR VALUES PLEASE.`\n",
        "    \n",
        "    \n",
        "3. Train the entire pipeline with a GridSearch\n",
        "    - Name your GridSearch object as `gs`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": false,
        "jupyter": {
          "outputs_hidden": true
        },
        "nbgrader": {
          "cell_type": "code",
          "checksum": "e1d18da8521d51d8bfc4b5b9d005fa34",
          "grade": false,
          "grade_id": "cell-e2beb0252d274bba",
          "locked": false,
          "schema_version": 3,
          "solution": true,
          "task": false
        },
        "id": "wQSGvMPndXEX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3f0bdc90-2083-41ee-931f-f20f8926b05a"
      },
      "source": [
        "%%time\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "# Name the gridsearch instance \"gs\"\n",
        "X = df.text\n",
        "y = df.stars\n",
        "\n",
        "tfidf= TfidfVectorizer(stop_words='english', tokenizer=None)\n",
        "\n",
        "rfc = RandomForestClassifier(random_state=42)\n",
        "\n",
        "pipe= Pipeline([('vect', tfidf),\n",
        "                 (\"clf\", rfc)])\n",
        "\n",
        "parameters = {\n",
        "    'vect__max_df' : (0.75,1.0),\n",
        "    'clf__max_depth' : (10,20)\n",
        "}\n",
        "\n",
        "gs = GridSearchCV(pipe,parameters, n_jobs=1)\n",
        "gs.fit(X,y)\n",
        "\n",
        "print(X.shape)\n",
        "print(y.shape)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(10000,)\n",
            "(10000,)\n",
            "CPU times: user 40.7 s, sys: 118 ms, total: 40.8 s\n",
            "Wall time: 40.9 s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "b9e2378efb868f104a4eb39e4f25563c",
          "grade": true,
          "grade_id": "cell-d07134c6fe5d056e",
          "locked": true,
          "points": 1,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "L6VtrG3VdXEX"
      },
      "source": [
        "# Visible Testing\n",
        "prediction = gs.predict([\"I wish dogs knew how to speak English.\"])[0]\n",
        "assert prediction in df.stars.values, 'You gs object should be able to accept raw text within a list. Did you include a vectorizer in your pipeline?'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2LXS2hgFdXEY"
      },
      "source": [
        "## Part 4: Topic Modeling\n",
        "\n",
        "Let's find out what those yelp reviews are saying! :D\n",
        "\n",
        "1. Estimate a LDA topic model of the review text\n",
        "    - Set num_topics to `5`\n",
        "    - Name your LDA model `lda`\n",
        "2. Create 1-2 visualizations of the results\n",
        "    - You can use the most important 3 words of a topic in relevant visualizations. Refer to yesterday's notebook to extract.\n",
        "3. In markdown, write 1-2 paragraphs of analysis on the results of your topic model\n",
        "\n",
        "When you instantiate your LDA model, it should look like this:\n",
        "\n",
        "```python\n",
        "lda = LdaModel(corpus=corpus,\n",
        "               id2word=id2word,\n",
        "               random_state=723812,\n",
        "               num_topics = num_topics,\n",
        "               passes=1\n",
        "              )\n",
        "\n",
        "```\n",
        "\n",
        "__*Note*__: You can pass the DataFrame column of text reviews to gensim. You do not have to use a generator."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vFSR5J6ndXEY"
      },
      "source": [
        "## Note about  pyLDAvis\n",
        "\n",
        "**pyLDAvis** is the Topic modeling package that we used in class to visualize the topics that LDA generates for us.\n",
        "\n",
        "You are welcomed to use pyLDAvis if you'd like for your visualization. However, **you MUST comment out the code that imports the package and the cell that generates the visualization before you submit your notebook to CodeGrade.**\n",
        "\n",
        "Although you should leave the print out of the visualization for graders to see (i.e. comment out the cell after you run it to create the viz)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y-VbHvcMdXEY"
      },
      "source": [
        "from gensim import corpora\n",
        "# Due to limited computationalresources on CodeGrader, use the non-multicore version of LDA\n",
        "from gensim.models.ldamodel import LdaModel\n",
        "import gensim\n",
        "import re"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b4sk018hdXEZ"
      },
      "source": [
        "### 1. Estimate a LDA topic model of the review tex"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "9514841e71735eaa255bccc53b257896",
          "grade": false,
          "grade_id": "cell-66331a185ff52f15",
          "locked": false,
          "schema_version": 3,
          "solution": true,
          "task": false
        },
        "id": "gn3vI420dXEZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ba6e62af-e66c-4be6-e415-da9d2e3a6801"
      },
      "source": [
        "# Remember to read the LDA docs for more information on the various class attirbutes and methods available to you\n",
        "# in the LDA model: https://radimrehurek.com/gensim/models/ldamodel.html\n",
        "\n",
        "# don't change this value\n",
        "num_topics = 5\n",
        "\n",
        "# use tokenize function you created earlier to create tokens\n",
        "tokens = df.text.apply(tokenize)\n",
        "# create a id2word object (hint: use corpora.Dictionary)\n",
        "id2word = corpora.Dictionary(tokens)\n",
        "# create a corpus object (hint: id2word.doc2bow)\n",
        "corpus = [id2word.doc2bow(text) for text in tokens]\n",
        "# instantiate an lda model\n",
        "lda = LdaModel(corpus = corpus,\n",
        "               id2word = id2word,\n",
        "               num_topics = num_topics,\n",
        "               random_state = 42,\n",
        "               passes = 1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:gensim.models.ldamodel:too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6O83w98odXEZ"
      },
      "source": [
        "#### Testing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "6479db0fa59c99d3ae3201c1f10ebca1",
          "grade": true,
          "grade_id": "cell-5a3c181311134fa9",
          "locked": true,
          "points": 1,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "BFVk29isdXEa"
      },
      "source": [
        "# Visible Testing\n",
        "assert lda.get_topics().shape[0] == 5, 'Did your model complete its training? Did you set num_topics to 5?'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TludRsgqdXEa"
      },
      "source": [
        "#### 2. Create 1-2 visualizations of the results"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "189591ed7b9e6e6146d59761fb418268",
          "grade": false,
          "grade_id": "cell-9b043e992fbd218c",
          "locked": false,
          "schema_version": 3,
          "solution": true,
          "task": false
        },
        "id": "NwgSK92ZdXEa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 374
        },
        "outputId": "96d6805a-c9aa-4c0e-d266-b53301512963"
      },
      "source": [
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import pyLDAvis.gensim_models\n",
        "\n",
        "# Use pyLDAvis (or a ploting tool of your choice) to visualize your results\n",
        "\n",
        "# YOUR CODE HERE\n",
        "#pyLDAvis.enable_notebook()\n",
        "#vis = pyLDAvis.gensim_models.prepare(lda, corpus, id2word)\n",
        "#vis"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-20-983b0e7fdf32>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mseaborn\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0msns\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mpyLDAvis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgensim_models\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# Use pyLDAvis (or a ploting tool of your choice) to visualize your results\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'pyLDAvis'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "f44a26c754500ff0bf585296075bf754",
          "grade": false,
          "grade_id": "cell-bf9e63d9645bba84",
          "locked": true,
          "points": 0,
          "schema_version": 3,
          "solution": false,
          "task": true
        },
        "id": "3iN2VUFCdXEa"
      },
      "source": [
        "#### 3. In markdown, write 1-2 paragraphs of analysis on the results of your topic model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LTfGQhLbxc-7"
      },
      "source": [
        "### Model Analysis:\n",
        "\n",
        "Today, we used a Latent Dirichlet Allocation model. This model tokenized our text data and created a dictionary based off those words. That dictionary was then taken into a corpus using list comprehension and crafted into an LDA model. We can see that the model has determined our topics 1 and 4 have high correlation(or have words that are similar in meaning) topic 2 is close to these two as well, however, our other topics seem to be much more spread apart. This may also be because of the limit in topics and our relevance level.\n",
        "\n",
        "\n",
        "The results of this model are subpar in my opinion. The text was not cleaned very well, there was a limit on how much we could tune the hyperparameters. This led to, what I would consider, a degredation in the true accuracy of the topics in our documents. I would be interested to see what we could accomplish by playing with the data and parameters."
      ]
    }
  ]
}